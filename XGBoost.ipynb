{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier  #GBM algorithm\n",
    "from sklearn import model_selection, metrics   #Additional scklearn functions\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold   #Perforing grid search\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import roc_curve, auc, cohen_kappa_score\n",
    "from itertools import cycle\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.41%\n",
      "Thresh=0.006, n=33, Accuracy: 99.39%\n",
      "Thresh=0.005, n=42, Accuracy: 99.41%\n",
      "Thresh=0.003, n=88, Accuracy: 99.44%\n",
      "Thresh=0.002, n=135, Accuracy: 99.41%\n",
      "Thresh=0.001, n=259, Accuracy: 99.41%\n",
      "Thresh=0.001, n=398, Accuracy: 99.39%\n",
      "Thresh=0.000, n=1803, Accuracy: 99.41%\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "train_df = pd.read_csv('LargeTrain.csv')\n",
    "\n",
    "X = train_df.ix[:,0:len(train_df.columns)-2]\n",
    "Y = train_df[\"Class\"]\n",
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
    "# fit model on all training data\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "# make predictions for test data and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "# Fit model using each importance as a threshold\n",
    "#thresholds = sorted(model.feature_importances_, reverse=True)\n",
    "thresholds = [0.006,0.005,0.003,0.002,0.001,0.0005,0.000]\n",
    "\n",
    "for thresh in thresholds:\n",
    "\t# select features using threshold\n",
    "\tselection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "\tselect_X_train = selection.transform(X_train)\n",
    "\t# train model\n",
    "\tselection_model = XGBClassifier()\n",
    "\tselection_model.fit(select_X_train, y_train)\n",
    "\t# eval model\n",
    "\tselect_X_test = selection.transform(X_test)\n",
    "\ty_pred = selection_model.predict(select_X_test)\n",
    "\tpredictions = [round(value) for value in y_pred]\n",
    "\taccuracy = accuracy_score(y_test, predictions)\n",
    "\tprint(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.00210, n=118, Accuracy: 99.470309%\n",
      "Thresh=0.00220, n=118, Accuracy: 99.470309%\n",
      "Thresh=0.00230, n=106, Accuracy: 99.498188%\n",
      "Thresh=0.00240, n=106, Accuracy: 99.498188%\n",
      "Thresh=0.00250, n=106, Accuracy: 99.498188%\n",
      "Thresh=0.00260, n=96, Accuracy: 99.442431%\n",
      "Thresh=0.00270, n=96, Accuracy: 99.442431%\n",
      "Thresh=0.00280, n=88, Accuracy: 99.442431%\n",
      "Thresh=0.00290, n=88, Accuracy: 99.442431%\n",
      "Thresh=0.00300, n=88, Accuracy: 99.442431%\n",
      "Thresh=0.00310, n=79, Accuracy: 99.470309%\n",
      "Thresh=0.00320, n=79, Accuracy: 99.470309%\n",
      "Thresh=0.00330, n=71, Accuracy: 99.414553%\n",
      "Thresh=0.00340, n=71, Accuracy: 99.414553%\n",
      "Thresh=0.00350, n=71, Accuracy: 99.414553%\n",
      "Thresh=0.00360, n=65, Accuracy: 99.358796%\n",
      "Thresh=0.00370, n=65, Accuracy: 99.358796%\n",
      "Thresh=0.00380, n=58, Accuracy: 99.358796%\n",
      "Thresh=0.00390, n=58, Accuracy: 99.358796%\n",
      "Thresh=0.00400, n=58, Accuracy: 99.358796%\n",
      "Thresh=0.00410, n=55, Accuracy: 99.275160%\n",
      "Thresh=0.00420, n=55, Accuracy: 99.275160%\n",
      "Thresh=0.00430, n=52, Accuracy: 99.275160%\n",
      "Thresh=0.00440, n=52, Accuracy: 99.275160%\n",
      "Thresh=0.00450, n=52, Accuracy: 99.275160%\n",
      "Thresh=0.00460, n=48, Accuracy: 99.303039%\n",
      "Thresh=0.00470, n=48, Accuracy: 99.303039%\n",
      "Thresh=0.00480, n=42, Accuracy: 99.414553%\n",
      "Thresh=0.00490, n=42, Accuracy: 99.414553%\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.linspace(0.0021, 0.0049, num = 29)\n",
    "\n",
    "for thresh in thresholds:\n",
    "\t# select features using threshold\n",
    "\tselection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "\tselect_X_train = selection.transform(X_train)\n",
    "\t# train model\n",
    "\tselection_model = XGBClassifier()\n",
    "\tselection_model.fit(select_X_train, y_train)\n",
    "\t# eval model\n",
    "\tselect_X_test = selection.transform(X_test)\n",
    "\ty_pred = selection_model.predict(select_X_test)\n",
    "\tpredictions = [round(value) for value in y_pred]\n",
    "\taccuracy = accuracy_score(y_test, predictions)\n",
    "\tprint(\"Thresh=%.5f, n=%d, Accuracy: %.6f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selection = SelectFromModel(model, threshold=0.0025, prefit=True)\n",
    "selected_X_train = selection.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7281, 1803)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = 'Class'\n",
    "IDcol = 'loc'\n",
    "predictors = [x for x in train_df.columns if x not in [target, IDcol]]\n",
    "\n",
    "my_scorer = metrics.make_scorer(metrics.f1_score, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stybill/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.99658, std: 0.00091, params: {'max_depth': 3, 'min_child_weight': 1},\n",
       "  mean: 0.99650, std: 0.00117, params: {'max_depth': 3, 'min_child_weight': 3},\n",
       "  mean: 0.99650, std: 0.00117, params: {'max_depth': 3, 'min_child_weight': 5},\n",
       "  mean: 0.99668, std: 0.00101, params: {'max_depth': 5, 'min_child_weight': 1},\n",
       "  mean: 0.99687, std: 0.00145, params: {'max_depth': 5, 'min_child_weight': 3},\n",
       "  mean: 0.99641, std: 0.00126, params: {'max_depth': 5, 'min_child_weight': 5},\n",
       "  mean: 0.99668, std: 0.00105, params: {'max_depth': 7, 'min_child_weight': 1},\n",
       "  mean: 0.99677, std: 0.00118, params: {'max_depth': 7, 'min_child_weight': 3},\n",
       "  mean: 0.99668, std: 0.00169, params: {'max_depth': 7, 'min_child_weight': 5},\n",
       "  mean: 0.99659, std: 0.00093, params: {'max_depth': 9, 'min_child_weight': 1},\n",
       "  mean: 0.99696, std: 0.00109, params: {'max_depth': 9, 'min_child_weight': 3},\n",
       "  mean: 0.99678, std: 0.00132, params: {'max_depth': 9, 'min_child_weight': 5},\n",
       "  mean: 0.99659, std: 0.00093, params: {'max_depth': 11, 'min_child_weight': 1},\n",
       "  mean: 0.99687, std: 0.00113, params: {'max_depth': 11, 'min_child_weight': 3},\n",
       "  mean: 0.99650, std: 0.00127, params: {'max_depth': 11, 'min_child_weight': 5},\n",
       "  mean: 0.99659, std: 0.00093, params: {'max_depth': 13, 'min_child_weight': 1},\n",
       "  mean: 0.99687, std: 0.00109, params: {'max_depth': 13, 'min_child_weight': 3},\n",
       "  mean: 0.99650, std: 0.00101, params: {'max_depth': 13, 'min_child_weight': 5},\n",
       "  mean: 0.99659, std: 0.00093, params: {'max_depth': 15, 'min_child_weight': 1},\n",
       "  mean: 0.99677, std: 0.00125, params: {'max_depth': 15, 'min_child_weight': 3},\n",
       "  mean: 0.99650, std: 0.00101, params: {'max_depth': 15, 'min_child_weight': 5},\n",
       "  mean: 0.99659, std: 0.00093, params: {'max_depth': 17, 'min_child_weight': 1},\n",
       "  mean: 0.99687, std: 0.00109, params: {'max_depth': 17, 'min_child_weight': 3},\n",
       "  mean: 0.99650, std: 0.00101, params: {'max_depth': 17, 'min_child_weight': 5},\n",
       "  mean: 0.99659, std: 0.00093, params: {'max_depth': 19, 'min_child_weight': 1},\n",
       "  mean: 0.99687, std: 0.00109, params: {'max_depth': 19, 'min_child_weight': 3},\n",
       "  mean: 0.99650, std: 0.00101, params: {'max_depth': 19, 'min_child_weight': 5}],\n",
       " {'max_depth': 9, 'min_child_weight': 3},\n",
       " 0.99695861162062127)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(3,20,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring=my_scorer,n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(train_df[predictors],train_df[target])\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test2 = {\n",
    " 'max_depth':[4,5,6],\n",
    " 'min_child_weight':[4,5,6]\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=9,\n",
    " min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(train_df[predictors],train_df[target])\n",
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-47017af87976>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m  objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n\u001b[1;32m      7\u001b[0m  param_grid = param_test3, scoring=my_scorer,n_jobs=4,iid=False, cv=5)\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mgsearch3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mgsearch3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgsearch3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgsearch3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/stybill/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/stybill/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/stybill/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/stybill/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_test3 = {\n",
    " 'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=9,\n",
    " min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test3, scoring=my_scorer,n_jobs=4,iid=False, cv=5)\n",
    "gsearch3.fit(train_df[predictors],train_df[target])\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
